{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welome to Tech Day NLP Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import os\n",
    "\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#    The first function\n",
    "#\n",
    "#    This function reads in the data from the csv file\n",
    "#    It then processes the data into separate dataframes\n",
    "#    These dataframes are contained within a dictionary\n",
    "#    The function returns the dictionary of dataframes\n",
    "#    for further processing\n",
    "###\n",
    "\n",
    "def read_data():\n",
    "    df = pd.read_csv('./file.csv')\n",
    "    \n",
    "    # Initialize an empty dictionary to become the dictionary of dataframes\n",
    "    d = {}    \n",
    "\n",
    "    # rename the columns from crap into good stuff based on actual column names from csv file\n",
    "    columns_good = list(df.iloc[6])\n",
    "    columns_bad = list(df.columns)\n",
    "    cols_dict = dict(zip(columns_bad, columns_good))\n",
    "    \n",
    "    df.rename(columns=cols_dict, inplace=True)\n",
    "\n",
    "    # Sanity check printing\n",
    "    # print(len(columns_good))\n",
    "    # print(len(columns_bad))\n",
    "    # cols_dict\n",
    "    \n",
    "    # Find all unique sources dropping garbage at top of CSV file\n",
    "    source_list = list(df.iloc[:,1].unique())[6:]    \n",
    "\n",
    "    # Sanity check\n",
    "    # print(source_list)    \n",
    "\n",
    "    # create a list of the columsn that contain date/time information (used in the for loop below)\n",
    "    dt_cols = ['Date(ET)', 'Time(ET)', 'LocalTime']\n",
    "    \n",
    "    # Create a for loop to build a dictionary of dataframes\n",
    "    for i in source_list:\n",
    "        d['{0}'.format(i)] = df[df.iloc[:,1] == i]\n",
    "        d['{0}'.format(i)].reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        # Fix the datetime dtype issue.\n",
    "        # This applies the to_datetime function to the three identified rows that contain date/time data\n",
    "        # \n",
    "        # IMPORTANT\n",
    "        # Because all sources were merged into ONE dataframe, some info in the date/time columns was NOT\n",
    "        # date/time info. For this reason, we use 'errors='ignore''. This keeps the original data that was\n",
    "        # NOT date/time data intact for when we split the data out into individual dataframes below\n",
    "        for col in dt_cols:\n",
    "            d['{0}'.format(i)][col] = pd.to_datetime(d['{0}'.format(i)][col], errors='ignore')\n",
    "    # for key in d.keys():\n",
    "        # print(key)\n",
    "        # d[key].iloc[:, 4:7] = d[key].iloc[:, 4:7].apply(pd.to_datetime, errors='ignore')\n",
    "\n",
    "    \n",
    "    # Create a for loop to drop columns that are completely NaN in EACH dataframe\n",
    "    # Also drop any rows that are completely NaN in EACH dataframe\n",
    "    for j in source_list:\n",
    "    #    print(d[j].shape)    # Sanity Check\n",
    "        d[j].dropna(axis=1, how='all', inplace=True)\n",
    "    #    print(d[j].shape)    # Sanity Check\n",
    "        d[j].dropna(axis=0, how='all', inplace=True)\n",
    "    #    print(d[j].shape)    # Sanity Check\n",
    "        d[j].reset_index(inplace=True, drop=True)\n",
    "        \n",
    "    # Return the dictionary of dataframes \n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hobor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hobor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\hobor\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NEWS', 'FORUMS', 'TUMBLR', 'TWITTER', 'INSTAGRAM'])\n",
      "11.759976863861084\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "df = read_data()\n",
    "print(df.keys())\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df.keys():\n",
    "    print(df[key].dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

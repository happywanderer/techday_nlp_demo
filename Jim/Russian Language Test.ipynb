{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Russian Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Russian language processing.\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "# >>> print(\" \".join(SnowballStemmer.languages)) # See which languages are supported\n",
    "# arabic danish dutch english finnish french german hungarian\n",
    "# italian norwegian porter portuguese romanian russian\n",
    "# spanish swedish\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nltk.tokenize.punkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.tokenize.punkt module\n",
    "# Punkt Sentence Tokenizer\n",
    "\n",
    "# This tokenizer divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation \n",
    "# words, collocations, and words that start sentences. It must be trained on a large collection of plaintext in the target \n",
    "# language before it can be used.\n",
    "\n",
    "# The NLTK data package includes a pre-trained Punkt tokenizer for English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\595872\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import nltk.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: ['Когда было много-много событий за последние два месяца, вот, буквально, каждый день по два - три мероприятия - конкурсы по разным дисциплинам, концерты - то инструменты, то хореография, экзамены в художественной школе, в новую школу по математике, дни рождения с родственниками и столами, участие в спектаклях... А мама что?', 'Мама родительский комитет и всё это организовывыла, включая выпускной.', 'В общем, итог прекрасный, два красных диплома ДШИ, три отделения закончили и новая школа на горизонте, но... как восстановиться?', 'Мне сейчас даже дышать неимоверно трудно(( Есть какая-то быстрая помощь?', 'Питание, физнагрузки или покой, что-то ещё?', 'Пока только Ламбруско могу пить) Может фильм посмотреть?', 'Ёлки, и это я ещё опытная, с многолетним стажем в РК))) И, надо же, так навернулась...))))))) Вот прям чувствую, что край - край((']\n",
      "\n",
      "After: ['Когда', 'было', 'много-много', 'событий', 'за', 'последние', 'два', 'месяца', ',', 'вот', ',', 'буквально', ',', 'каждый', 'день', 'по', 'два', '-', 'три', 'мероприятия', '-', 'конкурсы', 'по', 'разным', 'дисциплинам', ',', 'концерты', '-', 'то', 'инструменты', ',', 'то', 'хореография', ',', 'экзамены', 'в', 'художественной', 'школе', ',', 'в', 'новую', 'школу', 'по', 'математике', ',', 'дни', 'рождения', 'с', 'родственниками', 'и', 'столами', ',', 'участие', 'в', 'спектаклях', '...', 'А', 'мама', 'что', '?', 'Мама', 'родительский', 'комитет', 'и', 'всё', 'это', 'организовывыла', ',', 'включая', 'выпускной', '.', 'В', 'общем', ',', 'итог', 'прекрасный', ',', 'два', 'красных', 'диплома', 'ДШИ', ',', 'три', 'отделения', 'закончили', 'и', 'новая', 'школа', 'на', 'горизонте', ',', 'но', '...', 'как', 'восстановиться', '?', 'Мне', 'сейчас', 'даже', 'дышать', 'неимоверно', 'трудно', '(', '(', 'Есть', 'какая-то', 'быстрая', 'помощь', '?', 'Питание', ',', 'физнагрузки', 'или', 'покой', ',', 'что-то', 'ещё', '?', 'Пока', 'только', 'Ламбруско', 'могу', 'пить', ')', 'Может', 'фильм', 'посмотреть', '?', 'Ёлки', ',', 'и', 'это', 'я', 'ещё', 'опытная', ',', 'с', 'многолетним', 'стажем', 'в', 'РК', ')', ')', ')', 'И', ',', 'надо', 'же', ',', 'так', 'навернулась', '...', ')', ')', ')', ')', ')', ')', ')', 'Вот', 'прям', 'чувствую', ',', 'что', 'край', '-', 'край', '(', '(']\n"
     ]
    }
   ],
   "source": [
    "# Tokenizes the Russian text stored in the \"text\" variable and then prints the origianl text as well as the tokenized results.\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/russian.pickle')\n",
    "text = 'Когда было много-много событий за последние два месяца, вот, буквально, каждый день по два - три мероприятия - конкурсы по разным дисциплинам, концерты - то инструменты, то хореография, экзамены в художественной школе, в новую школу по математике, дни рождения с родственниками и столами, участие в спектаклях... А мама что? Мама родительский комитет и всё это организовывыла, включая выпускной. В общем, итог прекрасный, два красных диплома ДШИ, три отделения закончили и новая школа на горизонте, но... как восстановиться? Мне сейчас даже дышать неимоверно трудно(( Есть какая-то быстрая помощь? Питание, физнагрузки или покой, что-то ещё? Пока только Ламбруско могу пить) Может фильм посмотреть? Ёлки, и это я ещё опытная, с многолетним стажем в РК))) И, надо же, так навернулась...))))))) Вот прям чувствую, что край - край(('\n",
    "print(\"Before:\", tokenizer.tokenize(text))\n",
    "print('')\n",
    "print(\"After:\", nltk.word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizes the desired text and then converts the list or string to .Text.  This is required to use .concordance\n",
    "\n",
    "tokens = nltk.word_tokenize(tweet)\n",
    "tweet_words2 = nltk.Text(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allows a user to search for individual words within the text and returns every instance of the word along with the \n",
    "# phrase its found in.\n",
    "\n",
    "search_term = input('What term would you like to search for? ')\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tokenized_text = nltk.Text(tokens)\n",
    "tokenized_text.concordance(search_term)\n",
    "#tokenized_text.similar('много')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a variable that stores russian stopwords.\n",
    "\n",
    "ru_stopwords = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['и',\n",
       " 'в',\n",
       " 'во',\n",
       " 'не',\n",
       " 'что',\n",
       " 'он',\n",
       " 'на',\n",
       " 'я',\n",
       " 'с',\n",
       " 'со',\n",
       " 'как',\n",
       " 'а',\n",
       " 'то',\n",
       " 'все',\n",
       " 'она',\n",
       " 'так',\n",
       " 'его',\n",
       " 'но',\n",
       " 'да',\n",
       " 'ты',\n",
       " 'к',\n",
       " 'у',\n",
       " 'же',\n",
       " 'вы',\n",
       " 'за',\n",
       " 'бы',\n",
       " 'по',\n",
       " 'только',\n",
       " 'ее',\n",
       " 'мне',\n",
       " 'было',\n",
       " 'вот',\n",
       " 'от',\n",
       " 'меня',\n",
       " 'еще',\n",
       " 'нет',\n",
       " 'о',\n",
       " 'из',\n",
       " 'ему',\n",
       " 'теперь',\n",
       " 'когда',\n",
       " 'даже',\n",
       " 'ну',\n",
       " 'вдруг',\n",
       " 'ли',\n",
       " 'если',\n",
       " 'уже',\n",
       " 'или',\n",
       " 'ни',\n",
       " 'быть',\n",
       " 'был',\n",
       " 'него',\n",
       " 'до',\n",
       " 'вас',\n",
       " 'нибудь',\n",
       " 'опять',\n",
       " 'уж',\n",
       " 'вам',\n",
       " 'ведь',\n",
       " 'там',\n",
       " 'потом',\n",
       " 'себя',\n",
       " 'ничего',\n",
       " 'ей',\n",
       " 'может',\n",
       " 'они',\n",
       " 'тут',\n",
       " 'где',\n",
       " 'есть',\n",
       " 'надо',\n",
       " 'ней',\n",
       " 'для',\n",
       " 'мы',\n",
       " 'тебя',\n",
       " 'их',\n",
       " 'чем',\n",
       " 'была',\n",
       " 'сам',\n",
       " 'чтоб',\n",
       " 'без',\n",
       " 'будто',\n",
       " 'чего',\n",
       " 'раз',\n",
       " 'тоже',\n",
       " 'себе',\n",
       " 'под',\n",
       " 'будет',\n",
       " 'ж',\n",
       " 'тогда',\n",
       " 'кто',\n",
       " 'этот',\n",
       " 'того',\n",
       " 'потому',\n",
       " 'этого',\n",
       " 'какой',\n",
       " 'совсем',\n",
       " 'ним',\n",
       " 'здесь',\n",
       " 'этом',\n",
       " 'один',\n",
       " 'почти',\n",
       " 'мой',\n",
       " 'тем',\n",
       " 'чтобы',\n",
       " 'нее',\n",
       " 'сейчас',\n",
       " 'были',\n",
       " 'куда',\n",
       " 'зачем',\n",
       " 'всех',\n",
       " 'никогда',\n",
       " 'можно',\n",
       " 'при',\n",
       " 'наконец',\n",
       " 'два',\n",
       " 'об',\n",
       " 'другой',\n",
       " 'хоть',\n",
       " 'после',\n",
       " 'над',\n",
       " 'больше',\n",
       " 'тот',\n",
       " 'через',\n",
       " 'эти',\n",
       " 'нас',\n",
       " 'про',\n",
       " 'всего',\n",
       " 'них',\n",
       " 'какая',\n",
       " 'много',\n",
       " 'разве',\n",
       " 'три',\n",
       " 'эту',\n",
       " 'моя',\n",
       " 'впрочем',\n",
       " 'хорошо',\n",
       " 'свою',\n",
       " 'этой',\n",
       " 'перед',\n",
       " 'иногда',\n",
       " 'лучше',\n",
       " 'чуть',\n",
       " 'том',\n",
       " 'нельзя',\n",
       " 'такой',\n",
       " 'им',\n",
       " 'более',\n",
       " 'всегда',\n",
       " 'конечно',\n",
       " 'всю',\n",
       " 'между']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Когда\n",
      "много-много\n",
      "событий\n",
      "последние\n",
      "месяца\n",
      ",\n",
      ",\n",
      "буквально\n",
      ",\n",
      "каждый\n",
      "день\n",
      "-\n",
      "мероприятия\n",
      "-\n",
      "конкурсы\n",
      "разным\n",
      "дисциплинам\n",
      ",\n",
      "концерты\n",
      "-\n",
      "инструменты\n",
      ",\n",
      "хореография\n",
      ",\n",
      "экзамены\n",
      "художественной\n",
      "школе\n",
      ",\n",
      "новую\n",
      "школу\n",
      "математике\n",
      ",\n",
      "дни\n",
      "рождения\n",
      "родственниками\n",
      "столами\n",
      ",\n",
      "участие\n",
      "спектаклях\n",
      "...\n",
      "А\n",
      "мама\n",
      "?\n",
      "Мама\n",
      "родительский\n",
      "комитет\n",
      "всё\n",
      "это\n",
      "организовывыла\n",
      ",\n",
      "включая\n",
      "выпускной\n",
      ".\n",
      "В\n",
      "общем\n",
      ",\n",
      "итог\n",
      "прекрасный\n",
      ",\n",
      "красных\n",
      "диплома\n",
      "ДШИ\n",
      ",\n",
      "отделения\n",
      "закончили\n",
      "новая\n",
      "школа\n",
      "горизонте\n",
      ",\n",
      "...\n",
      "восстановиться\n",
      "?\n",
      "Мне\n",
      "дышать\n",
      "неимоверно\n",
      "трудно\n",
      "(\n",
      "(\n",
      "Есть\n",
      "какая-то\n",
      "быстрая\n",
      "помощь\n",
      "?\n",
      "Питание\n",
      ",\n",
      "физнагрузки\n",
      "покой\n",
      ",\n",
      "что-то\n",
      "ещё\n",
      "?\n",
      "Пока\n",
      "Ламбруско\n",
      "могу\n",
      "пить\n",
      ")\n",
      "Может\n",
      "фильм\n",
      "посмотреть\n",
      "?\n",
      "Ёлки\n",
      ",\n",
      "это\n",
      "ещё\n",
      "опытная\n",
      ",\n",
      "многолетним\n",
      "стажем\n",
      "РК\n",
      ")\n",
      ")\n",
      ")\n",
      "И\n",
      ",\n",
      ",\n",
      "навернулась\n",
      "...\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      ")\n",
      "Вот\n",
      "прям\n",
      "чувствую\n",
      ",\n",
      "край\n",
      "-\n",
      "край\n",
      "(\n",
      "(\n"
     ]
    }
   ],
   "source": [
    "# Iterates through tokenized text and removes the stopwords.\n",
    "\n",
    "tokenized_text = nltk.word_tokenize(text)\n",
    "\n",
    "for word in tokenized_text:\n",
    "    if word not in ru_stopwords:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the root word of a word.\n",
    "\n",
    "stemmer = SnowballStemmer(\"german\") # Choose a language\n",
    "stemmer.stem(\"Beir\") # Stem a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\595872\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: 'U' mode is deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "f=open('russian_sample.txt','rU')\n",
    "raw=f.read()\n",
    "tokens = nltk.word_tokenize(raw)\n",
    "#tokens = nltk.word_tokenize(raw), lang='rus')\n",
    "text_ru = nltk.Text(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
